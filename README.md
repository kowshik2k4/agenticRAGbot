# ğŸ¤– Agentic RAG Chatbot with Multi-Format Document QA (MCP-based)

This project implements a **Retrieval-Augmented Generation (RAG) chatbot** with a modular **agent-based architecture**. It supports **multi-format document uploads** and uses the **Model Context Protocol (MCP)** for communication between agents. The chatbot can answer user questions using uploaded PDFs, DOCX, PPTX, CSV, and TXT/Markdown files.

---

## ğŸ§  Architecture Overview

The system is divided into **three core agents**, each communicating via structured MCP messages:

```
User â†’ IngestionAgent â†’ RetrievalAgent â†’ LLMResponseAgent â†’ Answer
```

Each agent sends and receives MCP-style messages like:
```json
{
  "sender": "RetrievalAgent",
  "receiver": "LLMResponseAgent",
  "type": "RETRIEVAL_RESULT",
  "trace_id": "rag-123",
  "payload": {
    "retrieved_context": ["chunk1...", "chunk2..."],
    "query": "What KPIs were tracked in Q1?"
  }
}
```

---

## ğŸ§± Agent Roles

### 1. ğŸ” IngestionAgent
- Parses uploaded documents (PDF, DOCX, PPTX, CSV, TXT/MD).
- Extracts and chunks text for further processing.

### 2. ğŸ“¥ RetrievalAgent
- Embeds document chunks using **sentence-transformers**.
- Stores chunks in a **FAISS vector database**.
- Performs semantic similarity search to return relevant content.

### 3. ğŸ¤– LLMResponseAgent
- Builds a prompt using retrieved chunks + query.
- Calls **OpenAI GPT-3.5** to generate a final answer.
- Sends answer and source context back to the user.

---

## ğŸ“Š System Flow Diagram

```mermaid
sequenceDiagram
    participant User
    participant UI
    participant IngestionAgent
    participant RetrievalAgent
    participant LLMResponseAgent

    User->>UI: Upload documents + Ask question
    UI->>IngestionAgent: Send files
    IngestionAgent->>RetrievalAgent: Chunks (MCP message)
    RetrievalAgent->>LLMResponseAgent: Top-k context + query
    LLMResponseAgent->>UI: Answer + Source context
```

---

## ğŸ–¥ï¸ User Interface (Streamlit)

The frontend is built using **Streamlit**, offering:
- ğŸ“¤ Multi-document upload
- â“ Text input for multi-turn questions
- ğŸ“‘ Answer display with source context

---

## ğŸ§° Tech Stack

| Component | Technology |
|----------|-------------|
| UI       | Streamlit |
| Agents   | Python classes |
| Embeddings | HuggingFace `all-MiniLM-L6-v2` |
| Vector DB | FAISS |
| LLM      | OpenAI GPT-3.5 |
| Parsing  | PyMuPDF, python-docx, python-pptx, pandas |

---

## ğŸš€ Getting Started

### 1. Clone the repo
```bash
git clone https://github.com/your-username/agentic-rag-chatbot.git
cd agentic-rag-chatbot
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Set your OpenAI API key
```bash
export OPENAI_API_KEY=your-api-key
```

### 4. Run the app
```bash
streamlit run ui/app.py
```

---

## ğŸ“ File Structure

```
agentic_rag_chatbot/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ ingestion_agent.py
â”‚   â”œâ”€â”€ retrieval_agent.py
â”‚   â””â”€â”€ llm_response_agent.py
â”œâ”€â”€ mcp/
â”‚   â””â”€â”€ message.py
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ parser.py
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“¸ Screenshots

![UI Landing Page](image.png)
---

## ğŸ§ª Sample Use Case

**Uploaded Files**: `metrics.csv`, `q1_review.pdf`  
**Query**: â€œWhat KPIs were tracked in Q1?â€  
**Answer**: â€œThe tracked KPIs include retention rate, revenue, and conversion ratio.â€  
**Sources**: `metrics.csv`, `q1_review.pdf` (slide 2)

---

## âš™ï¸ Challenges Faced

- Ensuring compatibility across diverse document types
- Managing embeddings for large document sets
- Handling message flow between asynchronous agents

---

## ğŸ“ˆ Future Improvements

- Add summarization and ranking agents
- Use WebSockets for real-time updates
- Expand to multilingual document QA

---

## ğŸ“œ License

MIT License

---

## ğŸ¤ Acknowledgments

- OpenAI for GPT APIs
- HuggingFace for pretrained sentence-transformers
- Streamlit for easy UI integration
